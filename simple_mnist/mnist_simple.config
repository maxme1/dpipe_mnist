import argparse
from functools import partial
import sys


from torchvision import datasets, transforms
import torch.optim as optim
import torch

from mnist.pytorch_mnist import train_step, test_step, train_model, Net

def path_append():
    return sys.path.append('/home/deaddy/Repos/dpipe_mnist/')

# parser = argparse.ArgumentParser(description='PyTorch MNIST Example')
# parser.add_argument('--batch-size', type=int, default=64, metavar='N',
#                     help='input batch size for training (default: 64)')
# parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',
#                     help='input batch size for testing (default: 1000)')
# parser.add_argument('--epochs', type=int, default=10, metavar='N',
#                     help='number of epochs to train (default: 10)')
# parser.add_argument('--lr', type=float, default=0.01, metavar='LR',
#                     help='learning rate (default: 0.01)')
# parser.add_argument('--momentum', type=float, default=0.5, metavar='M',
#                     help='SGD momentum (default: 0.5)')
# parser.add_argument('--no-cuda', action='store_true', default=False,
#                     help='disables CUDA training')
# parser.add_argument('--seed', type=int, default=1, metavar='S',
#                     help='random seed (default: 1)')
# parser.add_argument('--log-interval', type=int, default=10, metavar='N',
#                     help='how many batches to wait before logging training status')
# args = parser.parse_args()
use_cuda = True#not args.no_cuda and torch.cuda.is_available()
seed = 1
#torch.manual_seed(seed)
batch_size = 64
test_batch_size = 1000
lr = 0.01
momentum = 0.5
epochs = 10
log_interval = 10

device = torch.device("cuda" if use_cuda else "cpu")

#kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True)
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=test_batch_size, shuffle=True, num_workers=1, pin_memory=True)


model = Net().to(device)
optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)
do_train_step = partial(train_step, model=model, device=device, train_loader=train_loader,
                      optimizer=optimizer, log_interval=log_interval)
do_test_step = partial(test_step, model=model, device=device, test_loader=test_loader)


do_experiment = (path_append(),
                 train_model(train_step=do_train_step,
                        test_step=do_test_step, epochs=epochs))

#do_experiment()
